## 4. Results {#results}

The performances of all four models are compared with a buy-and-hold strategy, which can be seen in figure \ref{fig:performance}. We observe that the FFN performs slightly better than our benchmark, while the other three clearly do not meet the benchmark. Looking more closely, it can be seen that one single decision (letter A in figure \ref{fig:performance}) of the FFN leads to the overperformance. If this event did not occur, the performance would also be worse than the benchmark. Further, a second decision (letter B in figure \ref{fig:performance}) worsens the performance and brings it back to a level similar to buy-and-hold. These two events appear to have occurred coincidentally. To test whether FFN systematically beats the buy-and-hold, it would be necessary to extend the time window and test different in- and out-of-samples and compare their performance. These findings strongly suggest that the individual decisions, and thus the performance of the examined neural networks, is determined by chance. 

```{r performance, fig.align='center', out.width='90%', fig.keep='last',fig.cap='Performance all', echo=FALSE, fig.width = 12, fig.height = 8}

#al together
name=c("Buy-and-hold","FNN","RNN","LSTM","GRU")
colors=c("black","red","blue","orange","green")
events <- xts(LETTERS[1:2], as.Date(c("2021-04-02","2021-04-12")))

plot(cbind(perfnew_rnn[,2],perfnew[,1],perfnew_rnn[,1],perfnew_lstm[,1],perfnew_gru[,1]),main="Performance comparison",col=colors)
addEventLines(events,srt=90,pos=2,lty=1,col = "orange",lwd=3,)

addLegend("bottomright", 
          legend.names=name,
          col=colors,
          lty=rep(1,1),
          lwd=rep(2,2),
          ncol=1,
          bg="white")

```







